Spark Note
@date 2018-8-16 14:25:08



Spark Master、Worker、Driver、Executor
Task, Job

Driver, Executor

本课从Driver和Worker的角度，也就是资源管理和分配的角度，来讲解Master、Worker、Driver、Executor工作流程。
程序运行的时候，Driver向Master申请资源；
Master让Worker给程序分配具体的Executor。
下面就是Driver具体的调用过程：
通过DAGScheduler划分阶段，形成一系列的TaskSet，然后传给TaskScheduler，把具体的Task交给Worker节点上的Executor的线程池处理。
线程池中的线程工作，通过BlockManager来读写数据。
这就是4大组件：Worker、Master、Executor、Driver之间的协同工作。

Master和Worker是守护进程
每个Worker上存在一个或者多个ExecutorBackend 进程。每个进程包含一个Executor对象，该对象持有一个线程池，每个线程可以执行一个task。
每个application包含一个 driver 和多个 executors，每个 executor里面运行的tasks都属于同一个application。
每个Worker上存在一个或者多个ExecutorBackend 进程。
每个进程包含一个Executor对象，该对象持有一个线程池，每个线程可以执行一个task。

Master 分配资源
Worker 执行任务

worker、executor、stage、task、partition关系
一个物理节点可以有一个或多个worker。
一个worker中可以有一个或多个executor，一个executor拥有多个cpu core和memory。
只有shuffle操作时才算作一个stage。
一个partition对应一个task。

如下示例，总共有4个stage（包括最后一个count），分区数10个，从而task也为10。假如总共的core数为2，那个这10个task会以每次2个的并行度执行。
    var a = new Array[(Int,Int)](10000)
    for (i <- 0 until 10000){
        a(i) = (i,i)
    }

    val rdd1 = sc.parallelize(a).coalesce(10,true)
    val rdd2= rdd1.map(x=>x)
    val rdd3 = rdd2.map(x=>x)
    val rdd4 = rdd3.reduceByKey((x,y)=>x+y)

    val rdd5 = rdd4.map(x=>x)
    val rdd6=rdd5.reduceByKey((x,y)=>x+y)

    val rdd7 = rdd6.map(x=>x)
    val rdd8=rdd7.reduceByKey((x,y)=>x+y)

    rdd8.count()








